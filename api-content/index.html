{"posts":[{"title":"install fluxcd in k8s 1.25.5","content":" install the flux cli: brew install fluxcd/tap/flux show the flux cli version: flux version create git repo on github set GITHUB_TOKEN env install the flux cd to k8s: flux bootstrap github --owner=&lt;you-github-name&gt; --repository=&lt;you-repo&gt; --path=./ --components-extra=image-reflector-controller,image-automation-controller --read-write-key --branch=main, Don't forget --components-extra=image-reflector-controller,image-automation-controller, Only when this parameter is used can image-related pods be created. wait flux cd pod up. ","link":"https://perror.dev/post/install-fluxcd-in-k8s-1255/"},{"title":"mysql error: rec.cc:391 thread ","content":"This error only in the mysql 8.0.30 version.see https://bugs.mysql.com/bug.php?id=107941 bug report. Upgrade mysql version to 8.0.31 to resolve this error ","link":"https://perror.dev/post/mysql-error-reccc391-thread/"},{"title":"如何清理 Kubernetes namespace 中的 finalizers 并成功删除 argocd namespace","content":"在删除 Kubernetes 集群中的资源时，我遵循以下步骤： 删除所有 deploy。 删除所有 configmap。 删除所有 namespace。 然而，我发现在删除 namespace 时出现了问题。尝试了官方提供的命令 kubectl delete -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml 但是 namespace 删除仍然被卡住了。我注意到该 namespace 下存在多个 argoproj.io/v1alpha1/applications 资源，并且所有资源都包含一个 finalizers 字段。通过搜索引擎，我了解到只有删除所有资源 YAML 文件中的 finalizers 字段才能解决 namespace 删除被卡住的问题。因此，我直接删除了 finalizers 字段并更新了所有资源，直到所有资源都被修改好为止。最终，namespace 能够被成功删除。 在 Kubernetes 中，删除某些资源时，这些资源可能具有关联的其他资源，这些关联资源需要被清理，以便能够顺利删除要删除的资源。当某个 namespace 中存在关联资源时，删除该 namespace 可能会失败。在这种情况下，Kubernetes 会在 namespace 对应的 finalizers 列表中添加一些条目，以确保所有关联资源被清理，然后再删除 namespace。在删除 namespace 时，Kubernetes 会检查 finalizers 列表中的所有条目，确保这些条目对应的所有资源已被清理，然后才会继续删除 namespace。 ","link":"https://perror.dev/post/shan-chu-argocd-namespace-fa-sheng-cuo-wu-some-content-in-the-namespace-has-finalizers-remaining-resources-finalizerargocdargoprojio-in-10-resource-instances/"},{"title":"helm 报错：another operation (install/upgrade/rollback) is in progress处理方法","content":"背景 使用flux cd来管理helmreleases 错误信息 单个helmrelease报错：another operation (install/upgrade/rollback) is in progress。 处理方式 运行 helm history &lt;name&gt; --namespace &lt;ns&gt; 运行： lux suspend hr &lt;name&gt; -n &lt;ns&gt; 选择status=pending-upgrade的版本，运行： helm uninstall &lt;name&gt; --namespace &lt;ns&gt; &lt;REVISION&gt; 运行： flux resume helmrelease &lt;name&gt; -n &lt;ns&gt; 搞定😊 ","link":"https://perror.dev/post/helm-bao-cuo-another-operation-installupgraderollback-is-in-progress-chu-li-fang-fa/"},{"title":"k8s PVC自动扩容实践 ","content":"依赖: k8s &gt;= 1.24 pvc-autoresizer &gt;= 0.5.0 一、安装 pvc-autoresizer build and push docker 镜像 git clone https://github.com/topolvm/pvc-autoresizer &amp;&amp; git checkout v0.5.0 &amp;&amp; cd pvc-autoresizer &amp;&amp; docker build -t pvc-autoresizer:0.5.0 . &amp;&amp; docker push pvc-autoresizer:0.5.0 添加 helm repo: helm repo add pvc-autoresizer https://topolvm.github.io/pvc-autoresizer/ <!-- more --> values.yaml 安装 pvc-autoresizer: helm install --create-namespace --namespace pvc-autoresizer pvc-autoresizer pvc-autoresizer/pvc-autoresizer --values ./values.yaml&quot; 检查是否成功 kubectl get pod -n pvc-autoresizer | grep pvc-autoresizer 二、 创建StatefulSet以及存储类 编写stateful-set.yaml: 部署: kubectl apply -f ./stateful-set.yaml 三、测试 进入pod中检查挂载目录大小, df -h 输出可以看到/data目录只使用了1%空间 写入文件测试自动扩容: dd if=/dev/zero of=1G.file bs=50M count=20 检查pvc-autoresizer pod 日志 再次检查pod挂载目录大小, 可以看见挂载目录已经使用了100%: /dev/sdf 975.9M 959.9M 0 100% /data 等待一会,再次查看挂载目录大小, 可以看见已经扩容成功: /dev/sdf 1.9G 960.4M 1007.4M 49% /data 😋😋😋😋😋😋 ","link":"https://perror.dev/post/k8s-pvc-zi-dong-kuo-rong-shi-jian/"},{"title":"redis的一些小知识","content":"redis的数据类型使用场合？ string：其value可以储存string以及数字类型，一般用于复杂的技术功能上。 hash：其value存放的是结构化的对象，它可以能方便的去操作某个字段，我使用他实现过用户行为数据缓存以及session功能。 list：类似python中的list数据类型，我一般使用他做消息队列或者分页功能。 set：该数据结构储存的是一系列无序、不重复的数据，这个还提供差集、交集等等功能， 我使用它为爬虫去重以及用户阅读过的文章功能。 sorted sort：有序集合储存一系列有序，不重复的数据，大多数场景都使用他做一个榜单的功能。 <!-- more --> redis的一些缺点 redis将所有数据放在内存中以便加快访问的速度，但是这也造成了redis容量受到物理内存大小的限制，所以redis对于一些海量数据场景有些乏力。 redis的在线扩容比较的麻烦，如果redis集群数量到达上限时，此时在线扩容是一个十分复杂的问题， 这大大提高了运维的成本。 redis的过期策略以及内存淘汰机制 redis采用了定时删除 + 惰性删除的方式来删除过期的数据，这里的定时删除，redis并非将所有设置过期时间的key都遍历一遍， 如果这样做将会消耗大量的CPU资源。redis采用了随机抽样，如果被抽到的key过期了就删除，但是如果仅仅时这样，那么有可能一些数据永远不会被抽到，这时redis引入了惰性删除， 在访问KEY的时候检查一下是否过期，过期就删除。 如果redis仅仅采用上面两种方式来删除数据，那么在极端情况下仍然会有数据不会被删除。redis还有内存淘汰策略，我最长使用的是allkeys-lru， 当redis内存到达上限时， 他从所有key中寻找最近最少使用的KEY删除。 大量数据插入redis应该怎么做？ 使用正常模式来插入显然不是一个明智的选择， 而使用管道的话某些客户端会被阻塞，导致不能在这期间执行其他的命令。比较好的方案是根据Redis协议生成一个文件，而后使用pipe mode去执行这个文件。参考Redis Mass Insertion。 redis分区？ redis的分区是指将数据分割成多个子集，分别保存到不同的redis实例中， 每一个redis实例都只保存了KEY的一个子集。 redis的分区在涉及多个key操作的时候，多数是不支持的，跟不要说多key事务操作。对于备份的情况也比较复杂。 redis分区有两种类型： 按照范围分区， 映射一定范围的对象到特定的Redis实例，但是这种并不长使用。 使用hash分区，其工作原理使用了hash表的原理，类似python dict。 redis如何做集群？ 推荐使用官方的redis cluster,其实现原理是：redis集群内部有2 ** 14个哈希槽， 当需要插入key时， 首先对key使用crc16算法计算出一个数字，在用此数字对2 ** 14 取余，该取余结果就是数据存放的哈希槽位置。而redis集群的节点管理这使用类似哨兵的机制来实现， 集群类节点通过相互ping来判断节点是否能够连接， 如果过半数节点都连接不上一个节点，则redis集群就会认定此节点宕机了。该方案确并不能保证数据的强一致性，所以在使用时一定不要将redis作为一个高可靠性的存储服务使用！ redis时如何做持久化？ redis支持两种持久化方案： 快照： 通过对配置文件的设置， 可以使得redis在N秒类M个key被修改时就将内存的数据以快照的方式写入到后缀为’.rdb’文件中。 aof: 每一次收到一次写的命令就将此命令追加到后缀为’.aof’文件中， 当redis重启时会通过重新执行文件中保存的写命令来在内存中重建整个数据库的内容。 ","link":"https://perror.dev/post/redis-de-yi-xie-xiao-zhi-shi/"},{"title":"cast类型转换库—go库推荐","content":"golang 中各种类型之间的转换实在是太过于繁琐，但是类型转换偏偏又是我们在开发过程中最常用的操作。同类型之间转换还稍微好一点，可以使用内置类型函数进行转换，但是想要转换不同的类型却需要引入不同的库， 而 cast 库正好解决了这一痛点，它提供了很多种的类型转换函数同我们使用， 通常的类型转换我们只需要引入这一个库就可以解决。 <!-- more --> 通常 go 中的类型转换都需要 err 变量来提示类型不可转换，cast 库提供了两种方法： 仅返回该类型的零值，不会返回 err 使用函数 To__E 将会返回一个 err 变量来告诉我们是否发生错误这样分开提供函数，极大的方便我们在开发中根据当前所需选择函数。 常用 API 列表： cast.StringToDate: 将常见的时间字符串转换为 time.Time 类型 cast.ToBoolSlice: 将任意类型的数组转换为 []bool 类型 cast.ToBool: 将任意类型转换为 bool 类型 cast.ToString: 将任意类型转换成 string cast.ToStringMap: 将任意类型 map 转换成 map[string]interface{} 更多的 API 可查看其文档：https://github.com/spf13/cast ","link":"https://perror.dev/post/cast-lei-xing-zhuan-huan-ku-go-ku-tui-jian/"},{"title":"redis sds详解","content":"什么是SDS？ SDS是redis构建的一种抽象类型，主要用于储存redis的默认字符串表示、AOF模块中的AOF缓冲区、客户端状态输入缓冲区。 <!-- more --> SDS有什么优点？ redis为什么不使用C的字符串？我们要先来看看C字符串中的缺点： C字符串不记录自身长度信息，为了获取字符串长度必须遍历整个字符串，时间复杂度为O(n)。 由于C字符串不记录自身长度，稍有不小心就会造成缓冲区溢出。 对于redis这种缓存类型数据库，对于缓存的Value是有可能经常的更改的。但是C字符串每次的增长或是缩小都需要一次内存的重分配操作。 redis数据库中缓存的内容不是特定的，有可能会是图片、音频等等文件的二进制数据，但是C字符串中的字符必须符合某种编码，且字符串中不能包含空格，这些限制也导致了redis不能使用C字符串来作为自身字符串的实现。 而SDS则将这些缺点都一一杜绝： 1. SDS记录了自身的长度信息，使得获取字符串长度的时间复杂度为O(1)。 2. SDS使用了预分配空间以及惰性空间释放的算法，解决了频繁分配内存的操作。 3. SDS由于保存了自身的长度，也导致了SDS不会像C一样按照’\\0’确定字符串的结尾。 SDS是如何实现的？ redis使用名为sdshdr的结构体表示SDS值： SDS遵循这C字符串以空字符结尾的惯例，以便能够重用C字符串中的函数，这个结尾的空字符串并不会增加len字段的值，例如现在需要使用SDS保存’golang’这个字符串，那么SDS对应的结构体是： 由于SDS记录了自身的长度，所以redis中获取字符串的长度只需要返回len字段的字段，其时间复杂度为O(1)，而对于C字符串经常发生的缓冲区溢出，SDS的空间分配策略完全杜绝了这种可能性：当redis需要对SDS字符串修改时，首先会检查SDS的空间是否满足修改所需的空间，如果不满足则将SDS空间扩容至满足该修改空间所需的容量，SDS空间扩容的算法如下： 这种扩容算法，减少了频繁的向系统申请内存的操作。SDS的空间释放并不是实时的，而是惰性释放：redis认为如果一个SDS的容量到达过N大小，则极有可能在其缩小后也有可能到达N，且惰性释放也减少了下次内存分配的可能，假如现在有一个’golang’字符串存储在redis中， 现在我们需要将’golang’修改为’go’，那么redis将会对SDS结构体将会是这样的： SDS提供了清理内存的API，我们可以在有需要时，调用该API以便真正的释放内存。 总结 redis只会使用C字符串作为字面量使用，大多数情况都使用SDS来表示字符串。 能够使用常数级复杂度获取字符串的长度。 杜绝了缓冲区溢出。 减少了字符串所需内存重新分配的次数。以及对于二进制数据安全，且兼容部分C字符串函数。 ","link":"https://perror.dev/post/redis-sds详解/"},{"title":"go的channel详解","content":"此片文章基于golang 1.12.1版本源码解析而成，chan源码位于go/src/runtime/chan.go文件中。 <!-- more --> channel是个什么？ chan 实际在源码中是一个结构体，该结构体结构如下： 其中sendx以及recvx为每次读取或者写入都需要将其加一，而recvq、sendq作用是有缓冲channel缓冲已满的情况下会将读取或是发送channel结构体放入其中。 channel的创建 创建一个chan我们会使用make函数来创建， 实际make函数调用了makechan函数创建，该函数签名如下：func makechan(t *chantype, size int) *hchan ，t是chan接收或者发送的数据类型， size则是make函数的第二个参数，指明了chan的缓冲大小，默认为0即无缓冲chan,返回hchan结构体的指针。创建channel时首先会检测t的大小，如果t的大小超过了65536个字节的话，将会触发错误，在这里我们可以实验一下，创建一个类型，使得该类型在被创建时大小就超过65535字节： 结构体创建完成后，在main函数中尝试在chan中传递这种数据:_ = make(chan A)，此时该代码将会编译不通过并发出错误：’ channel element type too large (&gt;64kB)'。当chan传递的数据类型大小符合要求后，将会根据t类型的特征去创建一定容量大小的内存空间，并将此片内存空间复制给buf，直到此时一个channel就算创建hao了。值得一提的是chan包中提供了一个名称为debugChan的变量，该变量默认为False， 当他为True时， 对chan操作时将会打印一些debug信息， 这将会帮助我们快速的发现由于chan发生的BUG。 向channel中发送数据 向chan中发送数据由chan.go: 142 chansend函数实现。该函数首先会检查当前channel等于nil并且是一个有缓冲通道则直接返回，如果是一个无缓存通道则调用proc.gp:284 gopark将当前的goroutine设置为waiting状态。随后检测channel时候已经准备好发送数据了，如果已经可以发送数据，则调用chan.go:264 send函数发送数据，send的作用主要是将要发送的数据copy到buf中，如果当前channel是无缓冲的，则调用lock加锁，阻塞当前goroutine，当前数据被接受后，调用goready通知runtime当前goroutine已经准备好再次运行了。如果channel是有缓冲的， 则直接返回。 从channel中接受数据 接受数据实际跟发送数据流程是一样的，唯一不同的是当前channel是有缓冲的时候并且channel中没有数据被发送时， 则直接将接受chan数据的变量地址存入到sendq结构体中。当有发送数据时发现recvq中有数据时， 直接将数据存入到这个结构体中的地址中，而不再会使用buf去copy数据。 总结 channel使用copy buf的方式来通信， 最后实现以通信的方式来共享内存。当一个goroutine阻塞的时候，系统线程会把它放入到hchan.sendq或者hchan.recvq list中， 该list中的sudog类型的结构题就是当前goruntine， 而这个sudog结构体中保存着一个变量，该变量保存着channel相关的指针。之前使用chan仅仅只是会使用，而不知其原理， 看了其源码，之前不理解的地方也恍然大悟。写这篇文章时是对着源码写的，可能有一些顺序上的矛盾。 ","link":"https://perror.dev/post/go的channel详解/"},{"title":"python IO多路复用实践","content":"最近几天一直在看tornado源码，发现torando虽然标榜使用异步模型实现， 但是实际上是使用IO多路复用实现的事件循环，为了能对 IO多路复用加深印象，决定自己实现一个简易的HTTP客户端对比一下同步客户端和IO多路复用客户端的性能差别。 <!-- more --> 废话少说， 现在先来看看同步客户端与IO多路复用客户端最直观的区别，首先使用tornado实现一个简单的服务端: 我们让服务端在处理请求时暂停1秒，以便能够更方便观察出两种方式实现的客户端区别，接下来先实现同步客户端: 启动服务端， 开始测试同步客户端请求服务端需要多少时间: 不出所料，请求三次由于服务器暂停了1秒总计使用时间为3秒。接下来实现IO多路复用客户端，来看看IO多路复用的表现: 运行客户端: 非常明显的看见时间上的区别，虽然代码看起来特别的复杂， 但是说的直白一点就是将每一个函数对应一个事件注册进sleelct中， 由sleect进行监控， 如果有事件触发就运行对应的函数。 我们分析下IO多路复用客户端代码： select = DefaultSelector() 该行代码返回了当前平台IO多路复用最佳实现方式，分别为：select、poll、epoll、dev/poll、kqueue, 由于我是使用win来测试所以DefaultSelector() 返回了select模型。 NoBlockClient.request 函数目的是创建一个非阻塞套接字连接至目标服务器， 并将当前套接字注册进select中， 当其状态为可写时， 运行NoBlockClient._send ，相当于一个回调函数。 NoBlockClient._send 负责将消息发送至已连接的服务器，最后如同NoBlockClient.request 一样注册事件选择回调函数。 NoBlockClient._recv 当注册事件为可读时， 将运行该函数， 读取服务器返回数据，至此一次完整的请求就结束了。 NoBlockClient.run 函数主要为了让select开始循环监听这些注册事件的状态，并运行回调函数。 selectors模块是对select模块封装，使得我们不用在意当前平台需要使用什么模型，而是直接返回当前平台最佳的模型，并将各个模型的api进行整合，让使用者能够更方便的写出跨平台代码。 最经常使用的几种模型包括: select,、poll、 epoll，接下来所以说这几种模型的区别，优缺点以及大概的实现方式。 select: select将被注册的事件放入一个列表中并拷贝到内核空间进行监听，如果这些事件其中一个有了变化那么select将再次把包含事件的列表拷贝进用户空间，这就造成了资源上的极大浪费， 如果select只监听一个或者两个事件还好， 但是当select需要监听的事件越来越多时，select的性能将会直线下降。而且select将时间拷贝到用户空间时并不会告诉用户哪一个事件被触发了，而是要用户自己去遍历。因为select监听的事件越多性能越差所以通常系统内核都会对select模型监听数量进行限制，在python源码中(github: selectmodule.c) 使用宏定义将win中select监听事件限制在了512, 当然select的最大优点则是几乎所有的平台都支持select。 poll: 其实现方式几乎与select相同， 所以select有的缺点poll也拥有，这里就不多说了。详情见poll事件机制。 epoll: epoll相比较select、poll有了质的改变，epoll将注册的事件都插入到了红黑树中，红黑树中的每一个节点都是一个注册的事件， 由于红黑树查询、插入、删除时间复杂度都是O(logn)，所以 epoll能够更加方便的对事件进行管理， 并且其在事件被触发时仅仅返回被触发的事件而不是像select全部返回， 这大大增加了效率。更加详细的epoll模型介绍见EPOLL的理解和深入分析。 ","link":"https://perror.dev/post/python-io-multiplexing/"},{"title":"python dict","content":"python的dict是一种映射类型, 底层使用了哈希表的方式来储存数据, 因此dict的查询速度的时间复杂度为O(1),这是一种典型的空间换时间的数据结构。 <!-- more --> 当我们创建一个key-value时，首先将哈希函数作用于key上获得一个整型数组，将这个整型数字与储存value数组的长度取余， 得到该数组的下标， 该下标就是value所存放的位置。 python在初始化dict时首先会申请一个大小为8KB左右的数组用来存放value（见dictobject.c第111行定义字典最小容量） ，如果数组位置不够存放则会再向系统申请两倍于当前容量的数组来存放value。 对于哈希冲突python选择了开放寻址法来解决：当产生哈希冲突时，通过探测函数计算出下一个候选位置，如果下一个候选位置还是有冲突，那么不断通过探测函数往下找，直到找个一个空槽来存放待插入元素。 dict的初始化在dictobject.PyDict_New:691该函数中完成： 在python3.6之后dict的键的顺序保持了插入时的顺序 dictobject.c:13 ","link":"https://perror.dev/post/python-dict/"},{"title":"python深拷贝浅拷贝","content":"说到python中的对象拷贝问题，还得看看is和==的区别： 可以看见a和b中的数值都是一样的，但是与is的结果却不是一样的，这是因为python中比较的是a和b的数值相等，is比较对象的标识是否相等。所以在python中我们经常会使用==来比较对象的数值时候相等， 判断对象绑定的值时候是None, 最好使用is。这里面有一个坑，一些新手经常犯的错误，空字符串，空列表，空字典，他们的都等于False，但是他们都不是（不等于）None,所以在判断一个字符串，列表，字典是否为空时， 不要用None来做比较,因为这些变量无论是从对象标识，数值都与None不相等。 我们平常是用的对象复制一般都是浅拷贝。copy模块为我们提供了copy(浅拷贝)，deepcopy(深拷贝）函数, 什么是浅拷贝： 浅拷贝就是将拷贝的对象引用拷贝一份，拷贝对象指向的是被拷贝对象的数值，简单的说就是，在原有数值上面再添加的一份引用。 什么是深拷贝： 深拷贝就是拷贝对象对被拷贝对象数值上复制一份，然后新建一个对象，这个新的对象数值，对象标识都是和被拷贝对象相等的. 基于这种现象，所以我们应该特别注意函数在使用可变参数作为默认参数，如不注意就会出现下面这种情况： 为了避免这种情况我们应该避免使用可变对象作为函数默认参数： 同时创建类初始化传参也是使用浅拷贝来传递的，这样就会出现这种情况： 在传入的参数改变的时候，类里面的变量的值页跟着改变了，这种情况时最难发现的。深拷贝/浅拷贝他们最大的区别就是:深拷贝拷贝父级对象及其子对象; 浅拷贝只拷贝父级对象. ","link":"https://perror.dev/post/python深拷贝浅拷贝/"},{"title":"python内置函数","content":"abs(x): 接受一个整数或浮点数作为参数，返回该参数的绝对值，如果该参数是一个复数，则返回复数的模。 all(iter): 接受一个可迭代类型，如果该参数内所有元素为真返回True，否则返回False。 <!-- more --> any(iter):接受一个可迭代类型为参数,如果该参数内任何元素为真,则返回True,否则返回False. asicc(object):接受一个对象, 将调用该对象的__repr__方法, 返回的字符串会将\\x,\\u,\\U进行转移输出. bin(x):接受一个整数作为参数, 并将该参数转换成以&quot;0b&quot;前缀的二进制字符串,如果x不是一个整数,那么将会调用对象的__index__方法的整数并转换成二进制. bool([x]):如果不传参数,则默认返回Fase,如果X是一个不是整数或浮点数则首先调用对象的__bool__方法, 如果对象的__bool__方法未定义,其次调用__len__方法,如果返回0则bool()返回False,否则返回True,如果对象__len__、__bool__方法都未定义则默认返回True bytearray([source[, encoding[, errors]]]):接受一个大于等于0小于256的整数或者一个可迭代类型、如果参数一个字符串,那么必须指定encoding. 返回一个新的字节数组.如果传入一个对象首先调用该对象__index__, 如果未定义__index__则调用对象__iter__方法. bytes([source[, encoding[, errors]]]): 如同bytearray使用方法, 不过该函数返回的一个不可变类型. callable(object):接受一个对象作为参数, 如果该参数是可以调用的则返回True, 否则返回False chr(i): 接受一个整数, 返回该整数对应的Unicode代码点的字符串,该整数必须大于等于0,小于等于1114112. @classmethod:装饰器, 作用于类方法上, 被装饰的方法将转换成类方法,类方法的一个参数将是类本身. complex([real[, imag]]): 创建一个值为 real + imag * j 的复数或者转化一个字符串或数为复数。如果第一个参数为字符串，则不需要指定第二个参数。 delattr(object, name): 接受一个对象以及一个字符串,删除该对象的name属性,也可以使用del object.name来实现. dir([object]):不传参数时, 返回当前范围内变量、方法和定义的类型列表,传入参数时返回该参数的所有的属性、方法, 如果该参数定义了__dir__方法, 则使用__dir__返回值, 否则该函数将尽可能的最大限度的收集该对象的方法以及属性. enumerate(iterable, start=0):接受一个可迭代类型以及一个可选int类型的参数, 返回一个枚举对象.如果指定了start则该可迭代对象的下边从start开始. eval(expression, globals=None, locals=None):接受一个字符串类型的表达式, 并执行该表达式,返回其值. float([x]): 接受一个可选整型、浮点型、对象或者字符串类型参数, 返回该参数的浮点类型数据,如果X是一个自定义对象那么将调用对象的__float__方法(仅提供用方法, 完整方法见:float). format(value[,format_spec]):格式化字符串函数, 接受不限个参数，位置可以不按顺序, 其数字格式化符号见菜鸟教程, 对于自定义对象, 则调用对象的__format__方法, 如果对象没有定义__format__则使用对象__str__方法. frozenset([iterable]): 接受一个可选的可迭代类型的参数, 返回一个frozenset对象, 该对象与set对象基本相似, 但是该对象是不可变的. getattr(object,name[,default]): 接受两个必选参数和一个可选参数, 该函数返回了object.name的值, 如果不存在name属性,并且没有传入default参数时则触发异常, 如果传入了default参数则没有找到name属性时返回default. hasattr(object, name): 接受两个必选参数, 检测object中是否有那么属性.如果有name属性返回True,否则返回False. hash(object): 接受一个必选参数, 返回该对象的整型哈希值, 如果时自定义对象则调用对象的__hash__方法. help([object]): 接受一个可选的参数, 该参数可以是任意的类型, 返回该对象的帮助文档, 如果是自定义对象, 则返回该函数或者类的注释.如果没有传入参数则拉起交互式的帮助系统 hex(x):接受一个整型作为必选参数, 返回该参数的16进制字符串, 该字符串以0x开头,如果x是一个自定义对象那么该对象必须实现__index__方法. id(object): 返回该对象在内存中的地址以整型返回. input([prompt]): 从标准输入中读取输入一回车键结束, 如果传入prompt, 则将prompt打印到标准输出中. int(x, base=10):将一个字符串或数字转换为整型,如果没有传入参数则返回0,如果传入传入了base则表示X是base进制的数字.如果X是一个自定义对象, 则调用__init__方法. isinstance(object, classinfo):如果object是classinfo的实例或者子类的实例, 返回True, 否则返回False.如果classinfo是一个元组, 那么object只要是元组中任意一个元素的子类的实例或者实例化都返回True. issubclass(class, classinfo):如果class是classinfo的子类返回true, 使用方法与isinstance相同. iter(object[,sentinel]):返回一个迭代器对象, 如果没有传入第二个参数, 那么object必须是实现了迭代协议或者序列协议否则将触发TypeError, 如果传入了sentinel参数那么object必须是可调用对象, 此时每迭代一次都调用object,如果object返回的值等于sentinel时,触发StopIteration异常. len(s): 接受一个序列或者集合类型对象, 返回其长度, 如果时自定义对象, 将会调用对象的__len__方法. locals():返回当前本地和只有变量的值. map(function,iterable…):返回一个迭代器, 该函数将function应用与每一个iterable元素上并返回直到可迭代对象耗尽. max(arg1,arg2,*args[,key]):接受多个位置参数或者一个可迭代对象, 返回其中最大的值. memoryview(obj): 返回obj的内存查看对象(对支持缓冲区协议的数据进行包装，在不需要复制对象基础上允许Python代码访问). min(arg1，arg2，* args[，key]): 接受多个位置参数或者一个可迭代对象, 返回其中最小的值. next(iterator[,default]): 通过调用iterator的__next__方法并返回其值. object(): 返回一个新的无任何特征的对象, object时所有class的基类. oct(x):接受一个整型作为参数返回以&quot;0o&quot;为前缀的八进制字符串,如果x是自定义对象, 则调用该对象的__index__方法. open(file,mode='r’,buffering=-1,encoding=None,errors=None,newline=None, closefd=True,opener=None):打开file文件并返回一个文件对象, 具体参数值见open. print(*objects,sep=’ ‘,end=’\\n’,file=sys.stdout,flush=False):将objects对象打印到标准输出中,每一个objects使用sep分割, 以end结束,对于自定义对象, 首先调用对象__str__方法, 如果没有定义__str__方法则调用__repr__方法. property(fget=None，fset=None，fdel=None，doc=None): 可作为装饰器使用也可作为函数使用.用于显示类属性的读取、设置以及删除. 作为函数使用时: range(start,stop[,step]):range并不是一个函数, range时一个不可变序列类型,返回一个迭代器对象. repr(object): 返回可打印的字符串,此函数尝试返回一个字符串，该字符串在传递时会产生具有相同值的对象eval()，否则表示形式是一个括在尖括号中的字符串，其中包含对象类型的名称以及其他信息通常包括对象的名称和地址。类可以通过定义__repr__()方法来控制此函数为其实例返回的内容. reversed(seq):接受一个可迭代类型, 返回该可迭代类型的反向迭代器. round(num, [, ndigits]): 返回num四舍五入精确到ndigits精度数字, 如果没有传入ndigits则返回最接近num的整数, 如果num时一个自定义对象, 则调用__round__方法. set([iterable]):返回一个新的set类型对象, 接受可选可迭代类型参数, 并将可迭代类型参数转换成set类型返回. setattr(object, name, value): 接受三个必选参数, 将object.name属性赋值为value. slice(start,stop[,step]):返回表示由指定的索引集的切片对象, 该对象为只读数据属性. key: 可选关键字参数,_key_指定一个参数的函数，该函数用于从_iterable中的_每个元素中提取比较键 reverse: 可选关键字参数, 如果设置为True，则列表元素将按照每个比较相反的方式进行排序. @staticmethod: 装饰器函数, 作用于类方法上, 将方法转换成静态方法. str(object=b’',encoding='utf-8’,errors='strict’):返回一个字符串类型的对象,如果object是一个自定义对象, 那么首先会调用对象的__str__方法, 如果没有实现__str__方法则调用__repr__方法. sum(iterable[,start]):如果没有传入_start_参数, 则将_iterable_所有的元素叠加后返回, 如果传入了_start_参数,则从_start_参数开始将_iterable_的元素从左至右的叠加. tuple([iterable]):返回一个元组对象, 接受一个可选的可迭代参数, 如果传入了该参数则将该参数转换成元组对象. type(name,bases,dict):只传入一个参数时将返回该参数的类型,使用三个参数，返回一个新类型对象,name则成为类对象的名称,base则表明了其父类, 可选的关键字参数则将成为类的属性.(type是类型实例关系的顶端, object是父子关系的顶端，所有的数据类型的父类都是它, Object是type的一个实例,Type是object的子类, 详细见type和object之间的关系) vars([object]):返回模块、类、实例、其他对象的__dict__属性. zip(*iterables):将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表,如果各个迭代器的元素个数不一致，则返回列表长度与最短的对象相同. import(name,globals=None,locals=None,fromlist=(),level=0):import 语句将会调用该函数,该函数导入模块_name_, 使用给定的_globals和_locals来确定如何解释包上下文中的名称. ","link":"https://perror.dev/post/python-nei-zhi-han-shu/"}]}